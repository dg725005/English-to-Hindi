{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de071ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dg725\\.conda\\envs\\new\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM # Its purpose is to automatically load a pre-trained \n",
    "                                                 # sequence-to-sequence language model that is \n",
    "                                                 # compatible with TensorFlow.\n",
    "\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\") # Print the TensorFlow version for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82597782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "# a model specifically trained by Helsinki NLP\n",
    "# to translate from English ('en') to French ('fr'). MarianMT models are\n",
    "# efficient and widely used for various language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6660284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 786.4/992.0 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 992.0/992.0 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d5433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dg725\\.conda\\envs\\new\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load the tokenizer associated with the pre-trained model.\n",
    "# The tokenizer is responsible for converting text into numerical IDs (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c137e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dg725\\.conda\\envs\\new\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\dg725\\.conda\\envs\\new\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load the pre-trained sequence-to-sequence model for conditional generation (translation).\n",
    "# TFAutoModelForSeq2SeqLM automatically selects the correct model architecture\n",
    "# (e.g., MarianMT model in this case) and loads its pre-trained weights, ensuring\n",
    "# it's compatible with TensorFlow. This model has an encoder (BERT-like)\n",
    "# and a decoder (GPT-like) component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd297679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text_to_translate):\n",
    "    inputs = tokenizer(text_to_translate, return_tensors=\"tf\", truncation=True,padding=True)\n",
    "\n",
    "    # Generate the translation using the model.\n",
    "    # 'generate' method is used for sequence generation tasks.\n",
    "    # 'inputs' are the tokenized input IDs.\n",
    "    # 'max_length' sets the maximum length of the generated output sequence.\n",
    "    # 'num_beams' is used for beam search decoding, which explores multiple\n",
    "    # possible next words to find a more probable sequence, leading to better translations.\n",
    "    # 'early_stopping=True' stops generation once all beam hypotheses have finished.\n",
    "    # 'no_repeat_ngram_size=2' prevents the generation of repeating n-grams (e.g., words or phrases)\n",
    "    # of size 2 or more, which helps in producing more natural-sounding translations.\n",
    "\n",
    "    translated_tokens = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length = 50,\n",
    "        num_beams = 5,\n",
    "        early_stopping = True,\n",
    "        no_repeat_ngram_size = 2\n",
    "    )\n",
    "\n",
    "    # Decode the generated tokens back into human-readable text.\n",
    "    # 'skip_special_tokens=True' removes special tokens (like [CLS], [SEP], [PAD])\n",
    "    # from the decoded output, resulting in clean text.\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "    # Return the translated text.\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b484865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is that one word that ignited to minds of Indians? \n",
      "\n",
      "वह एक शब्द क्या है जो आदिवासियों के मन में उभरता था?\n"
     ]
    }
   ],
   "source": [
    "#T = input('-> ')\n",
    "#print(T,'\\n')\n",
    "#print(translate_text(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94db6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d429bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "T = st.text_input(\"Enter text to translate:\")\n",
    "if T:\n",
    "    translated_text = translate_text(T)\n",
    "    st.write(f'Input Text: {T}')\n",
    "    st.write(f'Translated Text: {translated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10224f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09f496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f4eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068846af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff33b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e48b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3453baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bcde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ab395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d39b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7d9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0e820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3f02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484006a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b200b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0814d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
